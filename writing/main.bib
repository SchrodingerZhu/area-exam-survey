@book{bruegge2004object,
	title = {Object Oriented Software Engineering Using UML, Patterns, and Java},
	author = {Bruegge, Bernd and Dutoit, Allen H},
	year = {2009},
	publisher = {Prentice Hall}
}
@misc{terence_tao_lean_tour,
	title = {A slightly longer {Lean 4} proof tour},
	author = {Tao, Terence},
	url = {https://terrytao.wordpress.com/2023/12/05/a-slightly-longer-lean-4-proof-tour/},
	year = {2023}
}
@misc{Fermat_last_theorem,
	title = {{Fermat's Last Theorem} for regular primes},
	author = {LeanProver Community},
	url = {https://leanprover-community.github.io/flt-regular/blueprint/},
	year = {2024}
}
@article{Leroy-Compcert-CACM,
  author = {Xavier Leroy},
  title = {Formal verification of a realistic compiler},
  journal = {Communications of the ACM},
  year = 2009,
  volume = 52,
  number = 7,
  pages = {107--115},
  url = {http://xavierleroy.org/publi/compcert-CACM.pdf},
  urlpublisher = {http://doi.acm.org/10.1145/1538788.1538814},
  hal = {http://hal.archives-ouvertes.fr/inria-00415861/},
  pubkind = {journal-int-mono},
  abstract = {This paper reports on the development and formal verification (proof
of semantic preservation) of CompCert, a compiler from Clight (a
large subset of the C programming language) to PowerPC assembly code,
using the Coq proof assistant both for programming the compiler and
for proving its correctness.  Such a verified compiler is useful in
the context of critical software and its formal verification: the
verification of the compiler guarantees that the safety properties
proved on the source code hold for the executable compiled code as
well.}
}

@article{composable-verification,
author = {Zhang, Ling and Wang, Yuting and Wu, Jinhua and Koenig, J\'{e}r\'{e}mie and Shao, Zhong},
title = {Fully Composable and Adequate Verified Compilation with Direct Refinements between Open Modules},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {POPL},
url = {https://doi.org/10.1145/3632914},
doi = {10.1145/3632914},
abstract = {Verified compilation of open modules (i.e., modules whose functionality depends on other modules) provides a foundation for end-to-end verification of modular programs ubiquitous in contemporary software. However, despite intensive investigation in this topic for decades,the proposed approaches are still difficult to use in practice as they rely on assumptions about the internal working of compilers which make it difficult for external users to apply the verification results. We propose an approach to verified compositional compilation without such assumptions in the setting of verifying compilation of heterogeneous modules written in first-order languages supporting global memory and pointers. Our approach is based on the memory model of CompCert and a new discovery that a Kripke relation with a notion of memory protection can serve as a uniform and composable semantic interface for the compiler passes. By absorbing the rely-guarantee conditions on memory evolution for all compiler passes into this Kripke Memory Relation and by piggybacking requirements on compiler optimizations onto it, we get compositional correctness theorems for realistic optimizing compilers as refinements that directly relate native semantics of open modules and that are ignorant of intermediate compilation processes. Such direct refinements support all the compositionality and adequacy properties essential for verified compilation of open modules. We have applied this approach to the full compilation chain of CompCert with its Clight source language and demonstrated that our compiler correctness theorem is open to composition and intuitive to use with reduced verification complexity through end-to-end verification of non-trivial heterogeneous modules that may freely invoke each other (e.g.,mutually recursively).},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {72},
numpages = {31},
keywords = {Direct Refinements, Kripke Relations, Verified Compositional Compilation}
}
@article{10.1145/173262.155107,
author = {Grunwald, Dirk and Zorn, Benjamin and Henderson, Robert},
title = {Improving the cache locality of memory allocation},
year = {1993},
issue_date = {June 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/173262.155107},
doi = {10.1145/173262.155107},
abstract = {The allocation and disposal of memory is a ubiquitous operation in most programs. Rarely do programmers concern themselves with details of memory allocators; most assume that memory allocators provided by the system perform well. This paper presents a performance evaluation of the reference locality of dynamic storage allocation algorithms based on trace-driven simualtion of five large allocation-intensive C programs. In this paper, we show how the design of a memory allocator can significantly affect the reference locality for various applications. Our measurements show that poor locality in sequential-fit allocation algorithms reduces program performance, both by increasing paging and cache miss rates. While increased paging can be debilitating on any architecture, cache misses rates are also important for modern computer architectures. We show that algorithms attempting to be space-efficient by coalescing adjacent free objects show poor reference locality, possibly negating the benefits of space efficiency. At the other extreme, algorithms can expend considerable effort to increase reference locality yet gain little in total execution performance. Our measurements suggest an allocator design that is both very fast and has good locality of reference.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {177–186},
numpages = {10}
}

@inproceedings{locality-alloc,
author = {Grunwald, Dirk and Zorn, Benjamin and Henderson, Robert},
title = {Improving the cache locality of memory allocation},
year = {1993},
isbn = {0897915984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/155090.155107},
doi = {10.1145/155090.155107},
abstract = {The allocation and disposal of memory is a ubiquitous operation in most programs. Rarely do programmers concern themselves with details of memory allocators; most assume that memory allocators provided by the system perform well. This paper presents a performance evaluation of the reference locality of dynamic storage allocation algorithms based on trace-driven simualtion of five large allocation-intensive C programs. In this paper, we show how the design of a memory allocator can significantly affect the reference locality for various applications. Our measurements show that poor locality in sequential-fit allocation algorithms reduces program performance, both by increasing paging and cache miss rates. While increased paging can be debilitating on any architecture, cache misses rates are also important for modern computer architectures. We show that algorithms attempting to be space-efficient by coalescing adjacent free objects show poor reference locality, possibly negating the benefits of space efficiency. At the other extreme, algorithms can expend considerable effort to increase reference locality yet gain little in total execution performance. Our measurements suggest an allocator design that is both very fast and has good locality of reference.},
booktitle = {Proceedings of the ACM SIGPLAN 1993 Conference on Programming Language Design and Implementation},
pages = {177–186},
numpages = {10},
location = {Albuquerque, New Mexico, USA},
series = {PLDI '93}
}

@techreport{leijen2019mimalloc,
author = {Leijen, Daan and Zorn, Ben and de Moura, Leonardo},
title = {Mimalloc: Free List Sharding in Action},
institution = {Microsoft},
year = {2019},
month = {June},
abstract = {Modern memory allocators have to balance many simultaneous demands,
including performance, security, the presence of concurrency, and
application-specific demands depending on the context of their use. One
increasing use-case for allocators is as back-end implementations of
languages, such as Swift and Python, that use reference counting to
automatically deallocate objects. We present mimalloc, a memory allocator
that effectively balances these demands, shows significant performance
advantages over existing allocators, and is tailored to support languages
that rely on the memory allocator as a backend for reference counting.
Mimalloc combines several innovations to achieve this result. First, it
uses three page-local sharded free lists to increase locality, avoid
contention, and support a highly-tuned allocate and free fast path. These
free lists also support *temporal cadence*, which allows the allocator to
predictably leave the fast path for regular maintenance tasks such as
supporting deferred freeing, handling frees from non-local threads, etc.
While influenced by the allocation workload of the reference-counted Lean
and Koka programming language, we show that mimalloc has superior
performance to modern commercial memory allocators, including tcmalloc
and jemalloc, with speed improvements of 7% and 14%, respectively, on
redis, and consistently out performs over a wide range of sequential and
concurrent benchmarks. Allocators tailored to provide an efficient
runtime for reference-counting languages reduce the implementation burden
on developers and encourage the creation of innovative new language
designs.},
url = {https://www.microsoft.com/en-us/research/publication/mimalloc-free-list-sharding-in-action/},
number = {MSR-TR-2019-18},
}

@inproceedings{snmalloc,
author = {Li\'{e}tar, Paul and Butler, Theodore and Clebsch, Sylvan and Drossopoulou, Sophia and Franco, Juliana and Parkinson, Matthew J. and Shamis, Alex and Wintersteiger, Christoph M. and Chisnall, David},
title = {snmalloc: a message passing allocator},
year = {2019},
isbn = {9781450367226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3315573.3329980},
doi = {10.1145/3315573.3329980},
abstract = {snmalloc is an implementation of malloc aimed at workloads in which objects are typically deallocated by a different thread than the one that had allocated them. We use the term producer/consumer for such workloads. snmalloc uses a novel message passing scheme which returns deallocated objects to the originating allocator in batches without taking any locks. It also uses a novel bump pointer-free list data structure with which just 64-bits of meta-data are sufficient for each 64 KiB slab. On such producer/consumer benchmarks our approach performs better than existing allocators. Snmalloc is available at <a href="https://github.com/Microsoft/snmalloc">https://github.com/Microsoft/snmalloc</a>.},
booktitle = {Proceedings of the 2019 ACM SIGPLAN International Symposium on Memory Management},
pages = {122–135},
numpages = {14},
keywords = {message passing, Memory allocation},
location = {Phoenix, AZ, USA},
series = {ISMM 2019}
}

@inproceedings{haskell,
author = {Marlow, Simon and Harris, Tim and James, Roshan P. and Peyton Jones, Simon},
title = {Parallel generational-copying garbage collection with a block-structured heap},
year = {2008},
isbn = {9781605581347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1375634.1375637},
doi = {10.1145/1375634.1375637},
abstract = {We present a parallel generational-copying garbage collector implemented for the Glasgow Haskell Compiler. We use a block-structured memory allocator, which provides a natural granularity for dividing the work of GC between many threads, leading to a simple yet effective method for parallelising copying GC. The results are encouraging: we demonstrate wall-clock speedups of on average a factor of 2 in GC time on a commodity 4-core machine with no programmer intervention, compared to our best sequential GC.},
booktitle = {Proceedings of the 7th International Symposium on Memory Management},
pages = {11–20},
numpages = {10},
keywords = {parallel garbage collection},
location = {Tucson, AZ, USA},
series = {ISMM '08}
}

@inproceedings{ocaml-pm,
author = {Le Fessant, Fabrice and Maranget, Luc},
title = {Optimizing pattern matching},
year = {2001},
isbn = {1581134150},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/507635.507641},
doi = {10.1145/507635.507641},
abstract = {We present improvements to the backtracking technique of pattern-matching compilation. Several optimizations are introduced, such as commutation of patterns, use of exhaustiveness information, and control flow optimization through the use of labeled static exceptions and context information. These optimizations have been integrated in the Objective-Caml compiler. They have shown good results in increasing the speed of pattern-matching intensive programs, without increasing final code size.},
booktitle = {Proceedings of the Sixth ACM SIGPLAN International Conference on Functional Programming},
pages = {26–37},
numpages = {12},
location = {Florence, Italy},
series = {ICFP '01}
}

@inproceedings{ocaml,
author = {Doligez, Damien and Gonthier, Georges},
title = {Portable, unobtrusive garbage collection for multiprocessor systems},
year = {1994},
isbn = {0897916360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/174675.174673},
doi = {10.1145/174675.174673},
abstract = {We describe and prove the correctness of a new concurrent mark-and-sweep garbage collection algorithm. This algorithm derives from the classical on-the-fly algorithm from Dijkstra et al. [9]. A distinguishing feature of our algorithm is that it supports multiprocessor environments where the registers of running processes are not readily accessible, without imposing any overhead on the elementary operations of loading a register or reading or initializing a field. Furthermore our collector never blocks running mutator processes except possibly on requests for free memory; in particular, updating a field or creating or marking or sweeping a heap object does not involve system-dependent synchronization primitives such as locks. We also provide support for process creation and deletion, and for managing an extensible heap of variable-sized objects.},
booktitle = {Proceedings of the 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {70–83},
numpages = {14},
location = {Portland, Oregon, USA},
series = {POPL '94}
}

@article{erlang-1,
author = {Ungar, David},
title = {Generation Scavenging: A non-disruptive high performance storage reclamation algorithm},
year = {1984},
issue_date = {May 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {5},
issn = {0362-1340},
url = {https://doi.org/10.1145/390011.808261},
doi = {10.1145/390011.808261},
abstract = {Many interactive computing environments provide automatic storage reclamation and virtual memory to ease the burden of managing storage. Unfortunately, many storage reclamation algorithms impede interaction with distracting pauses. Generation Scavenging is a reclamation algorithm that has no noticeable pauses, eliminates page faults for transient objects, compacts objects without resorting to indirection, and reclaims circular structures, in one third the time of traditional approaches.We have incorporated Generation Scavenging in Berkeley Smalltalk(BS), our Smalltalk-80 implementation, and instrumented it to obtain performance data. We are also designing a microprocessor with hardware support for Generation Scavenging.},
journal = {SIGPLAN Not.},
month = {apr},
pages = {157–167},
numpages = {11},
keywords = {Generation, Grabage collection, Personnel computer, Real time, Scavenge, Smalltalk, Virtual memory, Workstation}
}

@article{erlang-2,
author = {Cheney, C. J.},
title = {A nonrecursive list compacting algorithm},
year = {1970},
issue_date = {Nov 1970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/362790.362798},
doi = {10.1145/362790.362798},
abstract = {A simple nonrecursive list structure compacting scheme or garbage collector suitable for both compact and LISP-like list structures is presented. The algorithm avoids the need for recursion by using the partial structure as it is built up to keep track of those lists that have been copied.},
journal = {Commun. ACM},
month = {nov},
pages = {677–678},
numpages = {2},
keywords = {LISP, compact list, garbage collection, list compacting}
}

@inproceedings{perceus,
author = {Reinking, Alex and Xie, Ningning and de Moura, Leonardo and Leijen, Daan},
title = {Perceus: garbage free reference counting with reuse},
year = {2021},
isbn = {9781450383912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453483.3454032},
doi = {10.1145/3453483.3454032},
abstract = {We introduce Perceus, an algorithm for precise reference counting with reuse and specialization. Starting from a functional core language with explicit control-flow, Perceus emits precise reference counting instructions such that (cycle-free) programs are _garbage free_, where only live references are retained. This enables further optimizations, like reuse analysis that allows for guaranteed in-place updates at runtime. This in turn enables a novel programming paradigm that we call _functional but in-place_ (FBIP). Much like tail-call optimization enables writing loops with regular function calls, reuse analysis enables writing in-place mutating algorithms in a purely functional way. We give a novel formalization of reference counting in a linear resource calculus, and prove that Perceus is sound and garbage free. We show evidence that Perceus, as implemented in Koka, has good performance and is competitive with other state-of-the-art memory collectors.},
booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {96–111},
numpages = {16},
keywords = {Reference Counting, Handlers, Algebraic Effects},
location = {Virtual, Canada},
series = {PLDI 2021}
}

@article{frame-limited,
author = {Lorenzen, Anton and Leijen, Daan},
title = {Reference counting with frame limited reuse},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {ICFP},
url = {https://doi.org/10.1145/3547634},
doi = {10.1145/3547634},
abstract = {The recently introduced _Perceus_ algorithm can automatically insert  
reference count instructions such that the resulting (cycle-free) program is  
_garbage free_: objects are freed at the very moment they can no longer be  
referenced. An important extension is reuse analysis. This optimization pairs  
objects of known size with fresh allocations of the same size and tries to  
reuse the object in-place at runtime if it happens to be unique. Unfortunately,  
current implementations of reuse analysis are fragile with respect to small  
program transformations, or can cause an arbitrary increase in the peak heap  
usage. We present a novel _drop-guided_ reuse algorithm that is simpler and  
more robust than previous approaches. Moreover, we generalize the linear  
resource calculus to precisely characterize garbage-free and frame-limited  
evaluations. On each function call, a frame-limited evaluation may hold on to  
memory longer if the size is bounded by a constant factor. Using this framework  
we show that our drop-guided reuse _is_ frame-limited and find that an  
implementation of our new reuse approach in Koka can provide significant  
speedups.},
journal = {Proc. ACM Program. Lang.},
month = {aug},
articleno = {103},
numpages = {24},
keywords = {Frame Limited, Koka, Reference Counting, Reuse}
}

@inproceedings{lean-4,
  author = {Moura, Leonardo de
and Ullrich, Sebastian},
  editor = {Platzer, Andr{\'e}
and Sutcliffe, Geoff},
  title = {The Lean 4 Theorem Prover and Programming Language},
  booktitle = {Automated Deduction -- CADE 28},
  year = {2021},
  publisher = {Springer International Publishing},
  address = {Cham},
  pages = {625--635},
  isbn = {978-3-030-79876-5},
  documenturl = {https://leanprover.github.io/papers/lean4.pdf}
}

@inproceedings{lxr,
author = {Zhao, Wenyu and Blackburn, Stephen M. and McKinley, Kathryn S.},
title = {Low-latency, high-throughput garbage collection},
year = {2022},
isbn = {9781450392655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3519939.3523440},
doi = {10.1145/3519939.3523440},
abstract = {To achieve short pauses, state-of-the-art concurrent copying collectors such as C4, Shenandoah, and ZGC use substantially more CPU cycles and memory than simpler collectors. They suffer from design limitations: i) concurrent copying with inherently expensive read and write barriers, ii) scalability limitations due to tracing, and iii) immediacy limitations for mature objects that impose memory overheads.  

This paper takes a different approach to optimizing responsiveness and throughput. It uses the insight that regular, brief stop-the-world collections deliver sufficient responsiveness at greater efficiency than concurrent evacuation. It introduces LXR, where stop-the-world collections use reference counting (Rc) and judicious copying. Rc delivers scalability and immediacy, promptly reclaiming young and mature objects. Rc, in a hierarchical Immix heap structure, reclaims most memory without any copying. Occasional concurrent tracing identifies cyclic garbage. LXR introduces: i) Rc remembered sets for judicious copying of mature objects; ii) a novel low-overhead write barrier that combines coalescing reference counting, concurrent tracing, and remembered set maintenance; iii) object reclamation while performing a concurrent trace; iv) lazy processing of decrements; and v) novel survival rate triggers that modulate pause durations.  

LXR combines excellent responsiveness and throughput, improving over production collectors. On the widely-used Lucene search engine in a tight heap, LXR delivers 7.8\texttimes{} better throughput and 10\texttimes{} better 99.99\% tail latency than Shenandoah. On 17 diverse modern workloads in a moderate heap, LXR outperforms OpenJDK’s default G1 on throughput by 4\% and Shenandoah by 43\%.},
booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {76–91},
numpages = {16},
keywords = {Garbage collection, Reference counting},
location = {San Diego, CA, USA},
series = {PLDI 2022}
}

@inproceedings{rc-immix,
author = {Shahriyar, Rifat and Blackburn, Stephen Michael and Yang, Xi and McKinley, Kathryn S.},
title = {Taking off the gloves with reference counting Immix},
year = {2013},
isbn = {9781450323741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2509136.2509527},
doi = {10.1145/2509136.2509527},
abstract = {Despite some clear advantages and recent advances, reference counting remains a poor cousin to high-performance tracing garbage collectors. The advantages of reference counting include a) immediacy of reclamation, b) incrementality, and c) local scope of its operations. After decades of languishing with hopelessly bad performance, recent work narrowed the gap between reference counting and the fastest tracing collectors to within 10\%. Though a major advance, this gap remains a substantial barrier to adoption in performance-conscious application domains. Our work identifies heap organization as the principal source of the remaining performance gap. We present the design, implementation, and analysis of a new collector, Rc Immix, that replaces reference counting's traditional free-list heap organization with the line and block heap structure introduced by the Immix collector. The key innovations of Rc Immix are 1) to combine traditional reference counts with per-line live object counts to identify reusable memory and 2) to eliminate fragmentation by integrating copying with reference counting of new objects and with backup tracing cycle collection. In Rc Immix, reference counting offers efficient collection and the line and block heap organization delivers excellent mutator locality and efficient allocation. With these advances, Rc Immix closes the 10\% performance gap, matching the performance of a highly tuned production generational collector. By removing the performance barrier, this work transforms reference counting into a serious alternative for meeting high performance objectives for garbage collected languages.},
booktitle = {Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages \& Applications},
pages = {93–110},
numpages = {18},
keywords = {reference counting, mark-region, immix, defragmentation},
location = {Indianapolis, Indiana, USA},
series = {OOPSLA '13}
}

@article{hoas,
author = {Pfenning, F. and Elliott, C.},
title = {Higher-order abstract syntax},
year = {1988},
issue_date = {July 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/960116.54010},
doi = {10.1145/960116.54010},
abstract = {We describe motivation, design, use, and implementation of higher-order abstract syntax as a central representation for programs, formulas, rules, and other syntactic objects in program manipulation and other formal systems where matching and substitution or unification are central operations. Higher-order abstract syntax incorporates name binding information in a uniform and language generic way. Thus it acts as a powerful link integrating diverse tools in such formal environments. We have implemented higher-order abstract syntax, a supporting matching and unification algorithm, and some clients in Common Lisp in the framework of the Ergo project at Carnegie Mellon University.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {199–208},
numpages = {10}
}

@inproceedings{linear,
  title={Linear Types can Change the World!},
  author={Philip Wadler},
  booktitle={Programming Concepts and Methods},
  year={1990},
  url={https://api.semanticscholar.org/CorpusID:58535510}
}

@Book{hottbook,
  author =    {The {Univalent Foundations Program}},
  title =     {Homotopy Type Theory: Univalent Foundations of Mathematics},
  publisher = {\url{https://homotopytypetheory.org/book}},
  address =   {Institute for Advanced Study},
  year =      2013}

@inproceedings{substructural,

  author={Pfenning, Frank and Simmons, Robert J.},

  booktitle={2009 24th Annual IEEE Symposium on Logic In Computer Science}, 

  title={Substructural Operational Semantics as Ordered Logic Programming}, 

  year={2009},

  volume={},

  number={},

  pages={101-110},

  keywords={Logic programming;Computer languages;Computer science;Parallel processing;Greedy algorithms;Calculus},

  doi={10.1109/LICS.2009.8}}

@article{fp2,
author = {Lorenzen, Anton and Leijen, Daan and Swierstra, Wouter},
title = {FP²: Fully in-Place Functional Programming},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {ICFP},
url = {https://doi.org/10.1145/3607840},
doi = {10.1145/3607840},
abstract = {As functional programmers we always face a dilemma: should we write purely  
functional code, or sacrifice purity for efficiency and resort to in-place  
updates? This paper identifies precisely when we can have the best of both  
worlds: a wide class of purely functional programs can be executed safely using  
in-place updates without requiring allocation, provided their arguments are not  
shared elsewhere.  

We describe a linear _fully in-place_ (FIP) calculus where we prove that we can  
always execute such functions in a way that requires no (de)allocation and uses  
constant stack space. Of course, such a calculus is only relevant if we can  
express interesting algorithms; we provide numerous examples of in-place  
functions on datastructures such as splay trees or finger trees, together with  
in-place versions of merge sort and quick sort.  

We also show how we can generically derive a map function over _any_ polynomial  
data type that is fully in-place. Finally, we have implemented the rules of the  
FIP calculus in the Koka language. Using the Perceus reference counting garbage  
collection, this implementation dynamically executes FIP functions in-place  
whenever possible.},
journal = {Proc. ACM Program. Lang.},
month = {aug},
articleno = {198},
numpages = {30},
keywords = {FBIP, Tail Recursion Modulo Cons}
}

@book{purely-functional-data-structures,
author = {Okasaki, Chris},
title = {Purely Functional Data Structures},
year = {1999},
isbn = {0521663504},
publisher = {Cambridge University Press},
address = {USA},
abstract = {From the Publisher:Most books on data structures assume an imperative language like C or C++. However, data structures for these languages do not always translate well to functional languages such as Standard ML, Haskell, or Scheme. This book describes data structures from the point of view of functional languages, with examples, and presents design techniques so that programmers can develop their own functional data structures. It includes both classical data structures, such as red-black trees and binomial queues, and a host of new data structures developed exclusively for functional languages. All source code is given in Standard ML and Haskell, and most of the programs can easily be adapted to other functional languages. This handy reference for professional programmers working with functional languages can also be used as a tutorial or for self-study.}
}

@misc{algoxy,
title = {Elementary Functional Algorithms},
url = {https://github.com/liuxinyu95/AlgoXY},
author = {Liu, Xinyu},
year = {2024},
}

@misc{advanced-data-structures,
title = {Advanced Data Structures (Lecture 1)},
url = {https://courses.csail.mit.edu/6.851/spring21/scribe/lec1.pdf},
author = {Demaine, Erik},
year = {2021},
}

@misc{proofs-as-programs,
title = {Proofs as Programs},
url = {https://www.cs.cmu.edu/~fp/courses/15317-f00/handouts/pap.pdf},
author = {Pfenning, Frank},
year = {2000},
}

@book{pragmatics, author = {Scott, Michael L.}, title = {Programming language pragmatics}, year = {2000}, isbn = {1558604421}, publisher = {Morgan Kaufmann Publishers Inc.}, address = {San Francisco, CA, USA} }

@book{optimal, author = {Asperti, Andrea and Guerrini, Stefano}, title = {The optimal implementation of functional programming languages}, year = {1999}, isbn = {0521621127}, publisher = {Cambridge University Press}, address = {USA} }

@article{construction,
author = {Coquand, Thierry and Huet, Gerard},
title = {The calculus of constructions},
year = {1988},
issue_date = {February/March 1988},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {76},
number = {2–3},
issn = {0890-5401},
url = {https://doi.org/10.1016/0890-5401(88)90005-3},
doi = {10.1016/0890-5401(88)90005-3},
journal = {Inf. Comput.},
month = {feb},
pages = {95–120},
numpages = {26}
}

@article{Pfenning2018,
author = "Frank  Pfenning and Christine  Paulin-Mohring",
title = "{Inductively defined types in the Calculus of Constructions}",
year = "2018",
month = "6",
url = "https://kilthub.cmu.edu/articles/journal_contribution/Inductively_defined_types_in_the_Calculus_of_Constructions/6606458",
doi = "10.1184/R1/6606458.v1"
}
@misc{rijke2022introduction,
      title={Introduction to Homotopy Type Theory}, 
      author={Egbert Rijke},
      year={2022},
      eprint={2212.11082},
      archivePrefix={arXiv},
      primaryClass={math.LO}
}
  

@misc{pi-forall,
title = {Pi-forall language},
url = {https://github.com/sweirich/pi-forall},
author = {Weirich, Stephanie},
year = {2023},
}

@misc{how-to-implement-ddt,
title = {How to implement dependent type theory I},
url = {https://math.andrej.com/2012/11/08/how-to-implement-dependent-type-theory-i/},
year = {2012},
author = {Bauer, Andrej},
}

@misc{elaberation-zoo,
title = {Elaboration Zoo},
url = {https://github.com/AndrasKovacs/elaboration-zoo/},
author = {Kovacs, Andras},
year = {2023},
}

@article{normalization-by-evaluation,
title = {Normalization by Evaluation: Dependent Types and Impredicativity},
url = {https://www.cse.chalmers.se/~abela/habil.pdf},
author = {Abel, Andreas},
year = {2013},
institution = {Ludwig-Maximilians-
Universität München},
}

@misc{how-to-code-your-own-type-theory,
title = {How to code your own type theory},
url = {https://www.jonmsterling.com/sterling-2022-hottest-colloqium.xml},
author = {Sterling, Jon},
year = {2022},
}

@inproceedings{NbPE,
author = {Dybjer, Peter and Filinski, Andrzej},
title = {Normalization and Partial Evaluation},
year = {2000},
isbn = {3540440445},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We give an introduction to normalization by evaluation and type-directed partial evaluation. We first present normalization by evaluation for a combinatory version of G del System T. Then we show normalization by evaluation for typed lambda calculus with and conversion. Finally, we introduce the notion of binding time, and explain the method of type-directed partial evaluation for a small PCF-style functional programming language. We give algorithms for both call-byname and call-by-value versions of this language.},
booktitle = {Applied Semantics, International Summer School, APPSEM 2000, Caminha, Portugal, September 9-15, 2000, Advanced Lectures},
pages = {137–192},
numpages = {56}
}

@misc{mmap,
author = {The Open Group},
url = {https://pubs.opengroup.org/onlinepubs/9699919799},
title = {mmap - map pages of memory},
year = 2018
}

@inproceedings{linear-haskell,
author = {Bernardy, Jean-Philippe and Boespflug, Mathieu and Newton, Ryan R. and Peyton Jones, Simon and Spiwack, Arnaud},
title = {Linear Haskell: practical linearity in a higher-order polymorphic language},
booktitle = {Principles of Programming Languages 2018 (POPL 2018)},
year = {2018},
month = {January},
abstract = {Linear type systems have a long and storied history, but not a clear path forward to integrate with existing languages such as OCaml or Haskell. In this paper, we study a linear type system designed with two crucial properties in mind: backward-compatibility and code reuse across linear and non-linear users of a library. Only then can the benefits of linear types permeate conventional functional programming. Rather than bifurcate types into linear and non-linear counterparts, we instead attach linearity to function arrows. Linear functions can receive inputs from linearly-bound values, but can also operate over unrestricted, regular values.

To demonstrate the efficacy of our linear type system - both how easy it can be integrated into an existing language implementation and how streamlined it makes it to write programs with linear types - we implemented our type system in GHC, the leading Haskell compiler, and demonstrate two kinds of applications of linear types: mutable data with pure interfaces; and enforcing protocols in I/O-performing functions.

Here is my talk at Curry On, July 2018},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/linear-haskell-practical-linearity-higher-order-polymorphic-language/},
}

@article{Lafont1997InteractionC,
  title={Interaction Combinators},
  author={Yves Lafont},
  journal={Inf. Comput.},
  year={1997},
  volume={137},
  pages={69-101},
  url={https://api.semanticscholar.org/CorpusID:16385844}
}

@inproceedings{rust-affine,
author = {Matsakis, Nicholas D. and Klock, Felix S.},
title = {The rust language},
year = {2014},
isbn = {9781450332170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663171.2663188},
doi = {10.1145/2663171.2663188},
abstract = {Rust is a new programming language for developing reliable and efficient systems. It is designed to support concurrency and parallelism in building applications and libraries that take full advantage of modern hardware. Rust's static type system is safe1 and expressive and provides strong guarantees about isolation, concurrency, and memory safety.Rust also offers a clear performance model, making it easier to predict and reason about program efficiency. One important way it accomplishes this is by allowing fine-grained control over memory representations, with direct support for stack allocation and contiguous record storage. The language balances such controls with the absolute requirement for safety: Rust's type system and runtime guarantee the absence of data races, buffer overflows, stack overflows, and accesses to uninitialized or deallocated memory.},
booktitle = {Proceedings of the 2014 ACM SIGAda Annual Conference on High Integrity Language Technology},
pages = {103–104},
numpages = {2},
keywords = {affine type systems, memory management, rust, systems programming},
location = {Portland, Oregon, USA},
series = {HILT '14}
}

@article{ghost-cell,
  author       = {Joshua Yanovski and
                  Hoang{-}Hai Dang and
                  Ralf Jung and
                  Derek Dreyer},
  title        = {GhostCell: separating permissions from data in Rust},
  journal      = {Proc. {ACM} Program. Lang.},
  volume       = {5},
  number       = {{ICFP}},
  pages        = {1--30},
  year         = {2021},
  url          = {https://doi.org/10.1145/3473597},
  doi          = {10.1145/3473597},
  timestamp    = {Sat, 30 Sep 2023 10:23:24 +0200},
  biburl       = {https://dblp.org/rec/journals/pacmpl/YanovskiDJD21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{Kappa,
  author =	{Castegren, Elias and Wrigstad, Tobias},
  title =	{{Reference Capabilities for Concurrency Control}},
  booktitle =	{30th European Conference on Object-Oriented Programming (ECOOP 2016)},
  pages =	{5:1--5:26},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-014-9},
  ISSN =	{1868-8969},
  year =	{2016},
  volume =	{56},
  editor =	{Krishnamurthi, Shriram and Lerner, Benjamin S.},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops-dev.dagstuhl.de/entities/document/10.4230/LIPIcs.ECOOP.2016.5},
  URN =		{urn:nbn:de:0030-drops-60998},
  doi =		{10.4230/LIPIcs.ECOOP.2016.5},
  annote =	{Keywords: Type systems, Capabilities, Traits, Concurrency, Object-Oriented}
}

@article{Pony,
author = {Clebsch, Sylvan and Franco, Juliana and Drossopoulou, Sophia and Yang, Albert Mingkun and Wrigstad, Tobias and Vitek, Jan},
title = {Orca: GC and type system co-design for actor languages},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {OOPSLA},
url = {https://doi.org/10.1145/3133896},
doi = {10.1145/3133896},
abstract = {ORCA is a concurrent and parallel garbage collector for actor programs, which does not require any STW steps, or synchronization mechanisms, and that has been designed to support zero-copy message passing and sharing of mutable data. ORCA is part of a runtime for actor-based languages, which was co-designed with the Pony programming language, and in particular, with its data race free type system. By co-designing an actor language with its runtime, it was possible to exploit certain language properties in order to optimize performance of garbage collection. Namely, ORCA relies on the guarantees of absence of race conditions in order to avoid read/write barriers, and it leverages the actor message passing, for synchronization among actors.  In this paper we briefly describe Pony and its type system. We use pseudo-code in order to introduce how ORCA allocates and deallocates objects, how it shares mutable data without requiring barriers upon data mutation, and how can immutability be used to further optimize garbage collection. Moreover, we discuss the advantages of co-designing an actor language with its runtime, and we demonstrate that ORCA can be implemented in a performant and scalable way through a set of micro-benchmarks, including a comparison with other well-known collectors.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {72},
numpages = {28},
keywords = {messages, actors}
}

@article{Verona,
author = {Arvidsson, Ellen and Castegren, Elias and Clebsch, Sylvan and Drossopoulou, Sophia and Noble, James and Parkinson, Matthew J. and Wrigstad, Tobias},
title = {Reference Capabilities for Flexible Memory Management},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3622846},
doi = {10.1145/3622846},
abstract = {Verona is a concurrent object-oriented programming language that organises all the objects in a program into a forest of isolated regions. Memory is managed locally for each region, so programmers can control a program's memory use by adjusting objects' partition into regions, and by setting each region's memory management strategy. A thread can only mutate (allocate, deallocate) objects within one active region---its "window of mutability". Memory management costs are localised to the active region, ensuring overheads can be predicted and controlled. Moving the mutability window between regions is explicit, so code can be executed wherever it is required, yet programs remain in control of memory use. An ownership type system based on reference capabilities enforces region isolation, controlling aliasing within and between regions, yet supporting objects moving between regions and threads. Data accesses never need expensive atomic operations, and are always thread-safe.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {270},
numpages = {31},
keywords = {type systems, ownership, memory management, isolation}
}

@misc{Miri,
author = {Ralf Jung and Hoang-Hai Dang and Derek Dreyer},
title = {An interpreter for Rust's mid-level intermediate representation },
year = {2024},
url = {https://github.com/rust-lang/miri}
}

@inproceedings{Uniqueness,
author = {Haller, Philipp and Odersky, Martin},
title = {Capabilities for uniqueness and borrowing},
year = {2010},
isbn = {3642141064},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {An important application of unique object references is safe and efficient message passing in concurrent object-oriented programming. However, to prevent the ill effects of aliasing, practical systems often severely restrict the shape of messages passed by reference. Moreover, the problematic interplay between destructive reads-often used to implement unique references-and temporary aliasing through "borrowed" references is exacerbated in a concurrent setting, increasing the potential for unpredictable run-time errors.This paper introduces a new approach to uniqueness. The idea is to use capabilities for enforcing both at-most-once consumption of unique references, and a flexible notion of uniqueness. The main novelty of our approach is a model of uniqueness and borrowing based on simple, unstructured capabilities. The advantages are: first, it provides simple foundations for uniqueness and borrowing. Second, it can be formalized using a relatively simple type system, for which we provide a complete soundness proof. Third, it avoids common problems involving borrowing and destructive reads, since unique references subsume borrowed references.We have implemented our type system as an extension to Scala. Practical experience suggests that our system allows type checking real-world actor-based concurrent programs with only a small number of additional type annotations.},
booktitle = {Proceedings of the 24th European Conference on Object-Oriented Programming},
pages = {354–378},
numpages = {25},
location = {Maribor, Slovenia},
series = {ECOOP'10}
}

@InProceedings{LinearUnique,
author="Marshall, Daniel
and Vollmer, Michael
and Orchard, Dominic",
editor="Sergey, Ilya",
title="Linearity and Uniqueness: An Entente Cordiale",
booktitle="Programming Languages and Systems",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="346--375",
abstract="Substructural type systems are growing in popularity because they allow for a resourceful interpretation of data which can be used to rule out various software bugs. Indeed, substructurality is finally taking hold in modern programming; Haskell now has linear types roughly based on Girard's linear logic but integrated via graded function arrows, Clean has uniqueness types designed to ensure that values have at most a single reference to them, and Rust has an intricate ownership system for guaranteeing memory safety. But despite this broad range of resourceful type systems, there is comparatively little understanding of their relative strengths and weaknesses or whether their underlying frameworks can be unified. There is often confusion about whether linearity and uniqueness are essentially the same, or are instead `dual' to one another, or somewhere in between. This paper formalises the relationship between these two well-studied but rarely contrasted ideas, building on two distinct bodies of literature, showing that it is possible and advantageous to have both linear and unique types in the same type system. We study the guarantees of the resulting system and provide a practical implementation in the graded modal setting of the Granule language, adding a third kind of modality alongside coeffect and effect modalities. We then demonstrate via a benchmark that our implementation benefits from expected efficiency gains enabled by adding uniqueness to a language that already has a linear basis.",
isbn="978-3-030-99336-8"
}

@inproceedings{cf-analysis,
author = {Allen, Frances E.},
title = {Control flow analysis},
year = {1970},
isbn = {9781450373869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800028.808479},
doi = {10.1145/800028.808479},
abstract = {Any static, global analysis of the expression and data relationships in a program requires a knowledge of the control flow of the program. Since one of the primary reasons for doing such a global analysis in a compiler is to produce optimized programs, control flow analysis has been embedded in many compilers and has been described in several papers. An early paper by Prosser [5] described the use of Boolean matrices (or, more particularly, connectivity matrices) in flow analysis. The use of “dominance” relationships in flow analysis was first introduced by Prosser and much expanded by Lowry and Medlock [6]. References [6,8,9] describe compilers which use various forms of control flow analysis for optimization. Some recent developments in the area are reported in [4] and in [7].The underlying motivation in all the different types of control flow analysis is the need to codify the flow relationships in the program. The codification may be in connectivity matrices, in predecessor-successor tables, in dominance lists, etc. Whatever the form, the purpose is to facilitate determining what the flow relationships are; in other words to facilitate answering such questions as: is this an inner loop?, if an expression is removed from the loop where can it be correctly and profitably placed?, which variable definitions can affect this use?In this paper the basic control flow relationships are expressed in a directed graph. Various graph constructs are then found and shown to codify interesting global relationships.},
booktitle = {Proceedings of a Symposium on Compiler Optimization},
pages = {1–19},
numpages = {19},
location = {Urbana-Champaign, Illinois}
}

@INBOOK{copy-avoidance,
  author={Warren, David S.},
  booktitle={Logic Programming: Proceedings of the Tenth International Conference on Logic Programming June 21-24, 1993, Budapest, Hungary}, 
  title={On Copy Avoidance in Single Assignment Languages}, 
  year={1993},
  volume={},
  number={},
  pages={393-407},
  keywords={},
  doi={}}

@misc{NIM,
  title = {Introduction to ARC/ORC in Nim},
  url = {https://nim-lang.org/blog/2020/10/15/introduction-to-arc-orc-in-nim.html},
  author = {Danil Yarantsev},
  year = {2020},
  }

@article{ORCA,
author = {Clebsch, Sylvan and Franco, Juliana and Drossopoulou, Sophia and Yang, Albert Mingkun and Wrigstad, Tobias and Vitek, Jan},
title = {Orca: GC and type system co-design for actor languages},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {OOPSLA},
url = {https://doi.org/10.1145/3133896},
doi = {10.1145/3133896},
abstract = {ORCA is a concurrent and parallel garbage collector for actor programs, which does not require any STW steps, or synchronization mechanisms, and that has been designed to support zero-copy message passing and sharing of mutable data. ORCA is part of a runtime for actor-based languages, which was co-designed with the Pony programming language, and in particular, with its data race free type system. By co-designing an actor language with its runtime, it was possible to exploit certain language properties in order to optimize performance of garbage collection. Namely, ORCA relies on the guarantees of absence of race conditions in order to avoid read/write barriers, and it leverages the actor message passing, for synchronization among actors. In this paper we briefly describe Pony and its type system. We use pseudo-code in order to introduce how ORCA allocates and deallocates objects, how it shares mutable data without requiring barriers upon data mutation, and how can immutability be used to further optimize garbage collection. Moreover, we discuss the advantages of co-designing an actor language with its runtime, and we demonstrate that ORCA can be implemented in a performant and scalable way through a set of micro-benchmarks, including a comparison with other well-known collectors.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {72},
numpages = {28},
keywords = {actors, messages}
}

@misc{cpp,
author = {The C++ Standards Committee},
title = {Programming Languages C++},
note = {Working Draft on C++23, ISO/IEC JTC1 SC22 WG21 N4950. Section 17.6.3.2 [new.delete.single]},
url = {https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/n4950.pdf},
year = {2023},
}

@inproceedings{state-monad,
author = {Jones, Mark P.},
title = {Functional Programming with Overloading and Higher-Order Polymorphism},
year = {1995},
isbn = {3540594515},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Advanced Functional Programming, First International Spring School on Advanced Functional Programming Techniques-Tutorial Text},
pages = {97–136},
numpages = {40}
}

@misc{mtl,
author = {MTL Authors},
title = {mtl: Monad classes for transformers, using functional dependencies},
year = {2024},
url = {https://hackage.haskell.org/package/mtl},
}

@misc{flt,
author = {FLT-regular Working Group},
title = {Fermat's Last Theorem for regular primes},
year = {2024},
url = {https://github.com/leanprover-community/flt-regular},
}

@misc{mathlib4,
author = {The Lean Community},
title = {mathlib4: The math library of Lean 4},
year = {2024},
url = {https://leanprover-community.github.io/mathlib4_docs/},
}

@misc{agda,
author = {The Agda Community},
title = {What is Agda?},
year = {2024},
url = {https://agda.readthedocs.io/en/latest/getting-started/what-is-agda.html},
}

@inproceedings{aggregate-problem,
author = {Hudak, Paul and Bloss, Adrienne},
title = {The aggregate update problem in functional programming systems},
year = {1985},
isbn = {0897911474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/318593.318660},
doi = {10.1145/318593.318660},
abstract = {We discuss the problem of efficiently implementing aggregates (contiguous data structures) such as arrays in functional programming systems. Simple changes to an aggregate conceptually involve making a new copy of the aggregate differing only in the changed component, but such copying can be expensive. We present both static and dynamic techniques for avoiding this copying, and argue that they allow one to program functionally using aggregates, without loss of efficiency over conventional programs.1},
booktitle = {Proceedings of the 12th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
pages = {300–314},
numpages = {15},
location = {New Orleans, Louisiana, USA},
series = {POPL '85}
}

@misc{scala-pr,
author = {Zeiger, Stefan},
title = {Rewrite Vector (now "radix-balanced finger tree vectors"), for performance},
url = {https://github.com/scala/scala/pull/8534},
year = {2019}
}

@inproceedings{rrb-vector,
author = {Stucki, Nicolas and Rompf, Tiark and Ureche, Vlad and Bagwell, Phil},
title = {RRB vector: a practical general purpose immutable sequence},
year = {2015},
isbn = {9781450336697},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2784731.2784739},
doi = {10.1145/2784731.2784739},
abstract = {State-of-the-art immutable collections have wildly differing performance characteristics across their operations, often forcing programmers to choose different collection implementations for each task. Thus, changes to the program can invalidate the choice of collections, making code evolution costly. It would be desirable to have a collection that performs well for a broad range of operations. To this end, we present the RRB-Vector, an immutable sequence collection that offers good performance across a large number of sequential and parallel operations. The underlying innovations are: (1) the Relaxed-Radix-Balanced (RRB) tree structure, which allows efficient structural reorganization, and (2) an optimization that exploits spatio-temporal locality on the RRB data structure in order to offset the cost of traversing the tree. In our benchmarks, the RRB-Vector speedup for parallel operations is lower bounded by 7x when executing on 4 CPUs of 8 cores each. The performance for discrete operations, such as appending on either end, or updating and removing elements, is consistently good and compares favorably to the most important immutable sequence collections in the literature and in use today. The memory footprint of RRB-Vector is on par with arrays and an order of magnitude less than competing collections.},
booktitle = {Proceedings of the 20th ACM SIGPLAN International Conference on Functional Programming},
pages = {342–354},
numpages = {13},
keywords = {Arrays, Data Structures, Immutable, Radix-Balanced, Relaxed-Radix-Balanced, Sequences, Trees, Vectors},
location = {Vancouver, BC, Canada},
series = {ICFP 2015}
}

@inproceedings{SISALSA,
  title={SISAL: streams and iteration in a single-assignment language. Language reference manual, Version 1. 1},
  author={James R. McGraw and Stephen K. Skedzielewski and Stephen J. Allan and Dale H. Grit and R. R. Oldehoeft and John R. W. Glauert and Ivan Dobes and Paul H. Hohensee},
  year={1983},
  url={https://api.semanticscholar.org/CorpusID:60925535}
}

@inproceedings{Koka,
  author       = {Daan Leijen},
  editor       = {Paul Blain Levy and
                  Neel Krishnaswami},
  title        = {Koka: Programming with Row Polymorphic Effect Types},
  booktitle    = {Proceedings 5th Workshop on Mathematically Structured Functional Programming,
                  MSFP@ETAPS 2014, Grenoble, France, 12 April 2014},
  series       = {{EPTCS}},
  volume       = {153},
  pages        = {100--126},
  year         = {2014},
  url          = {https://doi.org/10.4204/EPTCS.153.8},
  doi          = {10.4204/EPTCS.153.8},
  timestamp    = {Wed, 29 Sep 2021 08:56:00 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/Leijen14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{ullrich2020countingimmutablebeansreference,
      title={Counting Immutable Beans: Reference Counting Optimized for Purely Functional Programming}, 
      author={Sebastian Ullrich and Leonardo de Moura},
      year={2020},
      eprint={1908.05647},
      archivePrefix={arXiv},
      primaryClass={cs.PL},
      url={https://arxiv.org/abs/1908.05647}, 
}

@misc{JNI,
author = {The Java Community},
title = {Java Native Interface},
year = {2024},
url = {https://docs.oracle.com/en/java/javase/22/docs/specs/jni/index.html},
}


  




  

